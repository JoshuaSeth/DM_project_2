{"cells":[{"cell_type":"markdown","metadata":{"id":"4dKtqG7NjJ_r"},"source":["#Imports"]},{"cell_type":"markdown","metadata":{"id":"dleck9NgPKxx"},"source":["INSTALL MORE RECENT LIGHTGBM VERSION"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5FxSLgR5PKYn"},"outputs":[],"source":["!git clone --recursive https://github.com/Microsoft/LightGBM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yvT5OOxxR6Lq"},"outputs":[],"source":["!cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"MLOmqbK1R63k","executionInfo":{"status":"ok","timestamp":1653315065878,"user_tz":-120,"elapsed":2624,"user":{"displayName":"Patrycja Adamiak","userId":"10440301860444304322"}}},"outputs":[],"source":["import lightgbm as lgbm"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u2GVx3a_QitV","outputId":"f69db9f7-b050-4ba2-f4d0-5f410a0c416a","executionInfo":{"status":"ok","timestamp":1653314720620,"user_tz":-120,"elapsed":9,"user":{"displayName":"Patrycja Adamiak","userId":"10440301860444304322"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["3.3.2.99\n"]}],"source":["print(lgbm.__version__) # check version to be sure."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"HW-FvB1_XK_1","executionInfo":{"status":"ok","timestamp":1653315065879,"user_tz":-120,"elapsed":4,"user":{"displayName":"Patrycja Adamiak","userId":"10440301860444304322"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from datetime import datetime\n","#import lightgbm # this imports lightgbm version 2.2.3, which does not support some pretty nice features.\n","import matplotlib.pyplot as plt\n","from math import log10\n"]},{"cell_type":"markdown","metadata":{"id":"XW1iY7LAjImW"},"source":["#Loading and checking data"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lKal9sAkdr0m","outputId":"070e3cba-dcf1-43b6-dd4b-f51047ded4dc","executionInfo":{"status":"ok","timestamp":1653313115502,"user_tz":-120,"elapsed":2304,"user":{"displayName":"Patrycja Adamiak","userId":"10440301860444304322"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"]}],"source":["%reset"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MCoKpWhkChEr","executionInfo":{"status":"ok","timestamp":1653313346481,"user_tz":-120,"elapsed":15944,"user":{"displayName":"Patrycja Adamiak","userId":"10440301860444304322"}},"outputId":"4226b3ad-5daf-447b-e418-4448e1fd4a71"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"5J6EeE2WXOVE","executionInfo":{"status":"ok","timestamp":1653315101869,"user_tz":-120,"elapsed":32885,"user":{"displayName":"Patrycja Adamiak","userId":"10440301860444304322"}}},"outputs":[],"source":["df = pd.read_csv('drive/MyDrive/training_set_VU_DM.csv')#, nrows=100000)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"3KGeFza4dHAh","executionInfo":{"status":"ok","timestamp":1653315106043,"user_tz":-120,"elapsed":4211,"user":{"displayName":"Patrycja Adamiak","userId":"10440301860444304322"}}},"outputs":[],"source":["df['price_usd'].replace(to_replace=0.0, value=1, inplace=True) # some prices are 0.0, which is weird. replace with 0.1 for the log function\n","df['price_usd'] = df['price_usd'].apply(log10)\n","\n","df['visitor_hist_adr_usd'].replace(to_replace=0.0, value=1, inplace=True) # some prices are 0.0, which is weird.\n","df['visitor_hist_adr_usd'] = df['visitor_hist_adr_usd'].apply(log10)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"98g7_V4ShDKf","executionInfo":{"status":"ok","timestamp":1653315106045,"user_tz":-120,"elapsed":48,"user":{"displayName":"Patrycja Adamiak","userId":"10440301860444304322"}}},"outputs":[],"source":["### feature which highlights difference between the visitors historical data and the hotel cost\n","df['usd_diff'] = np.abs(df.visitor_hist_adr_usd.values - df.price_usd.values)\n","df['star_diff'] = np.abs(df.visitor_hist_starrating.values - df.prop_starrating.values)"]},{"cell_type":"markdown","metadata":{"id":"AibQQtYNjSjw"},"source":["#Making Training and evaluation data for the model"]},{"cell_type":"markdown","metadata":{"id":"gmm7VJOzX9Pw"},"source":["Adding mean property price as a feature to dataset"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":192},"id":"ALnF00bMR584","outputId":"798756f6-8f3c-4b54-dcb3-96ec6f056697","executionInfo":{"status":"ok","timestamp":1653315116035,"user_tz":-120,"elapsed":10035,"user":{"displayName":"Patrycja Adamiak","userId":"10440301860444304322"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"\\n### mean and std of 'prop_starrating' feature ###\\nsame_vals_df = pd.DataFrame()\\n_dict = df.groupby('prop_id')['prop_starrating'].mean().to_dict() # A dict with the operation applied to each group of the id \\nsame_vals_df['same_val_'+'prop_id'+'_'+'prop_starrating'+'_'+'avg'] = df['prop_id'].apply(get_from_dict, _dict=_dict)\\ndf = pd.concat([df, same_vals_df.set_index(df.index)], axis=1)\\n\\nsame_vals_df = pd.DataFrame()\\n_dict = df.groupby('prop_id')['prop_starrating'].std().to_dict() # A dict with the operation applied to each group of the id \\nsame_vals_df['same_val_'+'prop_id'+'_'+'prop_starrating'+'_'+'std'] = df['prop_id'].apply(get_from_dict, _dict=_dict)\\ndf = pd.concat([df, same_vals_df.set_index(df.index)], axis=1)\\n\\n### mean and std of 'prop_review_score' feature ###\\nsame_vals_df = pd.DataFrame()\\n_dict = df.groupby('prop_id')['prop_review_score'].mean().to_dict() # A dict with the operation applied to each group of the id \\nsame_vals_df['same_val_'+'prop_id'+'_'+'prop_review_score'+'_'+'avg'] = df['prop_id'].apply(get_from_dict, _dict=_dict)\\ndf = pd.concat([df, same_vals_df.set_index(df.index)], axis=1)\\n\\nsame_vals_df = pd.DataFrame()\\n_dict = df.groupby('prop_id')['prop_review_score'].std().to_dict() # A dict with the operation applied to each group of the id \\nsame_vals_df['same_val_'+'prop_id'+'_'+'prop_review_score'+'_'+'std'] = df['prop_id'].apply(get_from_dict, _dict=_dict)\\ndf = pd.concat([df, same_vals_df.set_index(df.index)], axis=1)\\n\\n### mean and std of 'prop_log_historical_price' feature ###\\nsame_vals_df = pd.DataFrame()\\n_dict = df.groupby('prop_id')['prop_log_historical_price'].mean().to_dict() # A dict with the operation applied to each group of the id \\nsame_vals_df['same_val_'+'prop_id'+'_'+'prop_log_historical_price'+'_'+'avg'] = df['prop_id'].apply(get_from_dict, _dict=_dict)\\ndf = pd.concat([df, same_vals_df.set_index(df.index)], axis=1)\\n\\nsame_vals_df = pd.DataFrame()\\n_dict = df.groupby('prop_id')['prop_log_historical_price'].std().to_dict() # A dict with the operation applied to each group of the id \\nsame_vals_df['same_val_'+'prop_id'+'_'+'prop_log_historical_price'+'_'+'std'] = df['prop_id'].apply(get_from_dict, _dict=_dict)\\ndf = pd.concat([df, same_vals_df.set_index(df.index)], axis=1)\\n\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":6}],"source":["def get_from_dict(x, _dict):\n","    '''There might be a better way to do this'''\n","    return _dict[x]\n","\n","\n","### mean and std of 'price_usd' feature per prop_id ###\n","same_vals_df = pd.DataFrame()\n","_dict = df.groupby('prop_id')['price_usd'].mean().to_dict() # A dict with the operation applied to each group of the id \n","same_vals_df['same_val_'+'prop_id'+'_'+'price_usd'+'_'+'avg'] = df['prop_id'].apply(get_from_dict, _dict=_dict)\n","df = pd.concat([df, same_vals_df.set_index(df.index)], axis=1)\n","\n","same_vals_df = pd.DataFrame()\n","_dict = df.groupby('prop_id')['price_usd'].std().to_dict() # A dict with the operation applied to each group of the id \n","same_vals_df['same_val_'+'prop_id'+'_'+'price_usd'+'_'+'std'] = df['prop_id'].apply(get_from_dict, _dict=_dict)\n","df = pd.concat([df, same_vals_df.set_index(df.index)], axis=1)\n","\n","'''\n","### mean and std of 'prop_starrating' feature ###\n","same_vals_df = pd.DataFrame()\n","_dict = df.groupby('prop_id')['prop_starrating'].mean().to_dict() # A dict with the operation applied to each group of the id \n","same_vals_df['same_val_'+'prop_id'+'_'+'prop_starrating'+'_'+'avg'] = df['prop_id'].apply(get_from_dict, _dict=_dict)\n","df = pd.concat([df, same_vals_df.set_index(df.index)], axis=1)\n","\n","same_vals_df = pd.DataFrame()\n","_dict = df.groupby('prop_id')['prop_starrating'].std().to_dict() # A dict with the operation applied to each group of the id \n","same_vals_df['same_val_'+'prop_id'+'_'+'prop_starrating'+'_'+'std'] = df['prop_id'].apply(get_from_dict, _dict=_dict)\n","df = pd.concat([df, same_vals_df.set_index(df.index)], axis=1)\n","\n","### mean and std of 'prop_review_score' feature ###\n","same_vals_df = pd.DataFrame()\n","_dict = df.groupby('prop_id')['prop_review_score'].mean().to_dict() # A dict with the operation applied to each group of the id \n","same_vals_df['same_val_'+'prop_id'+'_'+'prop_review_score'+'_'+'avg'] = df['prop_id'].apply(get_from_dict, _dict=_dict)\n","df = pd.concat([df, same_vals_df.set_index(df.index)], axis=1)\n","\n","same_vals_df = pd.DataFrame()\n","_dict = df.groupby('prop_id')['prop_review_score'].std().to_dict() # A dict with the operation applied to each group of the id \n","same_vals_df['same_val_'+'prop_id'+'_'+'prop_review_score'+'_'+'std'] = df['prop_id'].apply(get_from_dict, _dict=_dict)\n","df = pd.concat([df, same_vals_df.set_index(df.index)], axis=1)\n","\n","### mean and std of 'prop_log_historical_price' feature ###\n","same_vals_df = pd.DataFrame()\n","_dict = df.groupby('prop_id')['prop_log_historical_price'].mean().to_dict() # A dict with the operation applied to each group of the id \n","same_vals_df['same_val_'+'prop_id'+'_'+'prop_log_historical_price'+'_'+'avg'] = df['prop_id'].apply(get_from_dict, _dict=_dict)\n","df = pd.concat([df, same_vals_df.set_index(df.index)], axis=1)\n","\n","same_vals_df = pd.DataFrame()\n","_dict = df.groupby('prop_id')['prop_log_historical_price'].std().to_dict() # A dict with the operation applied to each group of the id \n","same_vals_df['same_val_'+'prop_id'+'_'+'prop_log_historical_price'+'_'+'std'] = df['prop_id'].apply(get_from_dict, _dict=_dict)\n","df = pd.concat([df, same_vals_df.set_index(df.index)], axis=1)\n","'''"]},{"cell_type":"markdown","metadata":{"id":"Jx8Q42-CYO_5"},"source":["for test set"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Y21uyHZkRHW6","executionInfo":{"status":"ok","timestamp":1653315120567,"user_tz":-120,"elapsed":4537,"user":{"displayName":"Patrycja Adamiak","userId":"10440301860444304322"}}},"outputs":[],"source":["### so i want to fill the competition NaN values with 0s\n","### all other variables i will set NaNs to -10\n","comp_columnns = [comp_col for comp_col in df.columns if comp_col.startswith('comp')]\n","df[comp_columnns] = df[comp_columnns].fillna(0)\n","df = df.fillna(-10)"]},{"cell_type":"markdown","metadata":{"id":"eVtnhcGW97kF"},"source":["for test set!"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"QwXO237896Jz","executionInfo":{"status":"ok","timestamp":1653311670324,"user_tz":-120,"elapsed":5479,"user":{"displayName":"Patrycja Adamiak","userId":"10440301860444304322"}}},"outputs":[],"source":["comp_columnns = [comp_col for comp_col in df_test.columns if comp_col.startswith('comp')]\n","df_test[comp_columnns] = df_test[comp_columnns].fillna(0)\n","df_test = df_test.fillna(-10)\n","df_test = df_test.drop(['date_time', 'site_id', 'random_bool', 'srch_id', 'prop_id', 'visitor_hist_starrating', 'visitor_hist_adr_usd'], axis=1, inplace=False)"]},{"cell_type":"code","source":["del same_vals_df"],"metadata":{"id":"__nGhn3aLjV0","executionInfo":{"status":"ok","timestamp":1653315120571,"user_tz":-120,"elapsed":35,"user":{"displayName":"Patrycja Adamiak","userId":"10440301860444304322"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["CV part\n"],"metadata":{"id":"27vru1k2VAFo"}},{"cell_type":"code","source":["idx=dict()\n","idx[0],idx[1],idx[2],idx[3],idx[4]=np.array_split(df['srch_id'].unique(),5)"],"metadata":{"id":"JZqujeHfESfb","executionInfo":{"status":"ok","timestamp":1653315120570,"user_tz":-120,"elapsed":37,"user":{"displayName":"Patrycja Adamiak","userId":"10440301860444304322"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def val_model(boosting='dart',num_leaves=255,min_data_in_leaf=1,min_sum_hessian_in_leaf=100, n_estimators=10, num_iterations=10, learning_rate=0.03, early_stopping_rounds=65,max_depth=-1):\n","  score=0\n","  for i in range(5):  \n","    df_train=df.loc[~df['srch_id'].isin(idx[i]),:]\n","    df_eval=df.loc[df['srch_id'].isin(idx[i]),:]\n","    qids_train = df_train.groupby('srch_id')['srch_id'].count().to_numpy()\n","    y_train = 5 * df_train['booking_bool'].values + df_train['click_bool'].values # booking_bool weighs for 5, clicking bool for 1\n","    X_train = df_train.drop(['date_time', 'random_bool', 'click_bool', 'booking_bool', 'position', 'site_id', 'gross_bookings_usd', 'srch_id', 'prop_id', 'visitor_hist_starrating', 'visitor_hist_adr_usd'], axis=1) # \n","\n","    qids_eval = df_eval.groupby('srch_id')['srch_id'].count().to_numpy()\n","    y_eval = 5 * df_eval['booking_bool'].values + df_eval['click_bool'].values\n","    X_eval = df_eval.drop(['date_time', 'random_bool', 'click_bool', 'booking_bool', 'position', 'site_id', 'gross_bookings_usd', 'srch_id', 'prop_id', 'visitor_hist_starrating', 'visitor_hist_adr_usd'], axis=1) # \n","    model = lgbm.LGBMRanker(objective='lambdarank', metric='ndcg', boosting='dart',\n","                          num_leaves=num_leaves, min_data_in_leaf=min_data_in_leaf, min_sum_hessian_in_leaf=min_sum_hessian_in_leaf, n_estimators=n_estimators,max_depth=max_depth,\n","                          num_iterations=num_iterations, learning_rate=learning_rate, early_stopping_rounds=early_stopping_rounds, device_type='gpu', seed=42)\n","    del df_train, df_eval\n","    model.fit(\n","        X=X_train,\n","        y=y_train,\n","        group=qids_train,\n","        eval_set=[(X_eval, y_eval)],\n","        eval_group=[qids_eval],\n","        eval_at=[5],\n","    )\n","    del qids_eval,qids_train,X_eval,X_train,y_eval,y_train\n","    score+=model.best_score_['valid_0']['ndcg@5']\n","    del model\n","  \n","  return(score)\n"],"metadata":{"id":"0deMC_DjEsYB","executionInfo":{"status":"ok","timestamp":1653316139038,"user_tz":-120,"elapsed":236,"user":{"displayName":"Patrycja Adamiak","userId":"10440301860444304322"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["val_model(num_leaves=10)"],"metadata":{"id":"1tc2pmwqH0KX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results=pd.DataFrame(columns=['num_leaves','max_depth','score'])\n","for num_leaves in [10,20]:\n","  for max_depth in [-1,4]:\n","    score=val_model(num_leaves=num_leaves,max_depth=max_depth)\n","    results=results.append({'num_leaves':num_leaves,'max_depth':max_depth,'score':score}, ignore_index=True)"],"metadata":{"id":"_nUgSPzqS0Z7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(results)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rsGE9Y5GW4VW","executionInfo":{"status":"ok","timestamp":1653316757515,"user_tz":-120,"elapsed":244,"user":{"displayName":"Patrycja Adamiak","userId":"10440301860444304322"}},"outputId":"bd0fadf5-65c6-4144-83f4-f542193d27de"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["   num_leaves  max_depth     score\n","0        10.0       -1.0  1.746999\n","1        10.0        4.0  1.744392\n","2        20.0       -1.0  1.776137\n","3        20.0        4.0  1.750639\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"LightGBM_modelCV.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}